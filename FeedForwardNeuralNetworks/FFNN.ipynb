{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# https://github.com/tuongv-1736461/EE399"
      ],
      "metadata": {
        "id": "CftBbox0RP15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Generate data points\n",
        "X = np.arange(0, 31)\n",
        "Y = np.array([30, 35, 33, 32, 34, 37, 39, 38, 36, 36, 37, 39, 42, 45, 45, 41, 40, 39, 42, 44, 47, 49, 50, 49, 46, 48, 50, 53, 55, 54, 53])\n",
        "\n",
        "# Define the neural network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(1, 10)\n",
        "        self.fc2 = nn.Linear(10, 10)\n",
        "        self.fc3 = nn.Linear(10, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Split the data into training and test sets\n",
        "X_train_1, Y_train_1 = X[:20], Y[:20]\n",
        "X_test_1, Y_test_1 = X[10:], Y[10:]\n",
        "\n",
        "X_train_2 = np.concatenate((X[:10], X[-10:]))\n",
        "Y_train_2 = np.concatenate((Y[:10], Y[-10:]))\n",
        "X_test_2 = X[10:-10]\n",
        "Y_test_2 = Y[10:-10]\n",
        "\n",
        "# Define function to train and evaluate a model \n",
        "def train_and_evaluate(X_train, Y_train, X_test, Y_test):\n",
        "  # Convert the training and test data to tensors\n",
        "  X_train_tensor = torch.Tensor(X_train).unsqueeze(1)\n",
        "  Y_train_tensor = torch.Tensor(Y_train).unsqueeze(1)\n",
        "  X_test_tensor = torch.Tensor(X_test).unsqueeze(1)\n",
        "  Y_test_tensor = torch.Tensor(Y_test).unsqueeze(1)\n",
        "\n",
        "  # Create a new neural network\n",
        "  net = Net()\n",
        "\n",
        "  # Define the loss function\n",
        "  criterion = nn.MSELoss()\n",
        "\n",
        "  # Define the optimizer\n",
        "  optimizer = optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "  # Set the number of epochs\n",
        "  num_epochs = 10\n",
        "\n",
        "  # Training loop\n",
        "  for epoch in range(num_epochs):\n",
        "      optimizer.zero_grad()\n",
        "      outputs = net(X_train_tensor)\n",
        "      loss = criterion(outputs, Y_train_tensor)\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # Print the loss at every 100th epoch\n",
        "      if (epoch+1) % 100 == 0:\n",
        "          print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item()}')\n",
        "\n",
        "  # Evaluate the model on training and test data\n",
        "  with torch.no_grad():\n",
        "      train_predictions = net(X_train_tensor)\n",
        "      train_loss = criterion(train_predictions, Y_train_tensor)\n",
        "      test_predictions = net(X_test_tensor)\n",
        "      test_loss = criterion(test_predictions, Y_test_tensor)\n",
        "\n",
        "  # Print the training and test errors\n",
        "  print(f'Train Error: {train_loss.item()}')\n",
        "  print(f'Test Error: {test_loss.item()}')\n",
        "\n",
        "# Call the function to train and evaluate the model\n",
        "train_and_evaluate(X_train_1, Y_train_1, X_test_1, Y_test_1)\n",
        "train_and_evaluate(X_train_2, Y_train_2, X_test_2, Y_test_2)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPiD1y1-Z6NG",
        "outputId": "6d8d9f3b-f073-467e-8e1e-aa4cf54e6ba1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Error: 16.6630859375\n",
            "Test Error: 91.0152359008789\n",
            "Train Error: 142.67678833007812\n",
            "Test Error: 66.91342163085938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "# Define the neural network architecture\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(20, 128)   # Adjusting input size to 20\n",
        "        self.fc2 = nn.Linear(128, 64)\n",
        "        self.fc3 = nn.Linear(64, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x.float()))  # Convert input to float\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "# Load the MNIST dataset and apply transformations\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transforms.ToTensor())\n",
        "\n",
        "# Get the data tensors from the datasets\n",
        "X_train = train_dataset.data.float()  # Convert image data to float\n",
        "Y_train = train_dataset.targets\n",
        "\n",
        "# Reshape the input images for PCA (flatten each image)\n",
        "X_train_flattened = X_train.view(X_train.size(0), -1)\n",
        "\n",
        "# Compute PCA on the flattened images\n",
        "pca = PCA(n_components=20)  # Number of PCA modes to compute (20 in this case)\n",
        "X_train_pca = pca.fit_transform(X_train_flattened)\n",
        "\n",
        "# Create data loaders for training and testing\n",
        "train_data = torch.utils.data.TensorDataset(torch.from_numpy(X_train_pca), Y_train)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_data, batch_size=64, shuffle=True)\n",
        "\n",
        "# Initialize the network and define the loss function and optimizer\n",
        "net = Net()\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "# Train the network\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i+1) % 100 == 0:\n",
        "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))\n",
        "\n",
        "# Test the network\n",
        "test_data = test_dataset.data.float()  # Convert image data to float\n",
        "X_test_flattened = test_data.view(test_data.size(0), -1)\n",
        "X_test_pca = pca.transform(X_test_flattened)  # Apply PCA transformation on test data\n",
        "Y_test = test_dataset.targets\n",
        "\n",
        "test_data = torch.utils.data.TensorDataset(torch.from_numpy(X_test_pca), Y_test)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_data, batch_size=64, shuffle=False)\n",
        "\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.float()  # Convert images to float\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ebHDorAM_GAB",
        "outputId": "4fe3db50-640f-4f08-d234-5ead5d829292"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Step [100/938], Loss: 1.1059\n",
            "Epoch [1/10], Step [200/938], Loss: 1.4078\n",
            "Epoch [1/10], Step [300/938], Loss: 1.0622\n",
            "Epoch [1/10], Step [400/938], Loss: 0.9033\n",
            "Epoch [1/10], Step [500/938], Loss: 0.6788\n",
            "Epoch [1/10], Step [600/938], Loss: 0.5067\n",
            "Epoch [1/10], Step [700/938], Loss: 0.3921\n",
            "Epoch [1/10], Step [800/938], Loss: 0.4774\n",
            "Epoch [1/10], Step [900/938], Loss: 0.3019\n",
            "Epoch [2/10], Step [100/938], Loss: 0.4841\n",
            "Epoch [2/10], Step [200/938], Loss: 0.4570\n",
            "Epoch [2/10], Step [300/938], Loss: 0.2417\n",
            "Epoch [2/10], Step [400/938], Loss: 0.3802\n",
            "Epoch [2/10], Step [500/938], Loss: 0.2282\n",
            "Epoch [2/10], Step [600/938], Loss: 0.2884\n",
            "Epoch [2/10], Step [700/938], Loss: 0.2668\n",
            "Epoch [2/10], Step [800/938], Loss: 0.3875\n",
            "Epoch [2/10], Step [900/938], Loss: 0.2695\n",
            "Epoch [3/10], Step [100/938], Loss: 0.1215\n",
            "Epoch [3/10], Step [200/938], Loss: 0.2390\n",
            "Epoch [3/10], Step [300/938], Loss: 0.2877\n",
            "Epoch [3/10], Step [400/938], Loss: 0.2700\n",
            "Epoch [3/10], Step [500/938], Loss: 0.2743\n",
            "Epoch [3/10], Step [600/938], Loss: 0.3847\n",
            "Epoch [3/10], Step [700/938], Loss: 0.2242\n",
            "Epoch [3/10], Step [800/938], Loss: 0.1285\n",
            "Epoch [3/10], Step [900/938], Loss: 0.3482\n",
            "Epoch [4/10], Step [100/938], Loss: 0.1372\n",
            "Epoch [4/10], Step [200/938], Loss: 0.4742\n",
            "Epoch [4/10], Step [300/938], Loss: 0.3425\n",
            "Epoch [4/10], Step [400/938], Loss: 0.2300\n",
            "Epoch [4/10], Step [500/938], Loss: 0.1638\n",
            "Epoch [4/10], Step [600/938], Loss: 0.1756\n",
            "Epoch [4/10], Step [700/938], Loss: 0.2319\n",
            "Epoch [4/10], Step [800/938], Loss: 0.1897\n",
            "Epoch [4/10], Step [900/938], Loss: 0.0378\n",
            "Epoch [5/10], Step [100/938], Loss: 0.0420\n",
            "Epoch [5/10], Step [200/938], Loss: 0.1421\n",
            "Epoch [5/10], Step [300/938], Loss: 0.1546\n",
            "Epoch [5/10], Step [400/938], Loss: 0.2314\n",
            "Epoch [5/10], Step [500/938], Loss: 0.1882\n",
            "Epoch [5/10], Step [600/938], Loss: 0.2268\n",
            "Epoch [5/10], Step [700/938], Loss: 0.0896\n",
            "Epoch [5/10], Step [800/938], Loss: 0.3950\n",
            "Epoch [5/10], Step [900/938], Loss: 0.3620\n",
            "Epoch [6/10], Step [100/938], Loss: 0.1481\n",
            "Epoch [6/10], Step [200/938], Loss: 0.0860\n",
            "Epoch [6/10], Step [300/938], Loss: 0.1842\n",
            "Epoch [6/10], Step [400/938], Loss: 0.4705\n",
            "Epoch [6/10], Step [500/938], Loss: 0.0705\n",
            "Epoch [6/10], Step [600/938], Loss: 0.0502\n",
            "Epoch [6/10], Step [700/938], Loss: 0.2620\n",
            "Epoch [6/10], Step [800/938], Loss: 0.1925\n",
            "Epoch [6/10], Step [900/938], Loss: 0.1124\n",
            "Epoch [7/10], Step [100/938], Loss: 0.2733\n",
            "Epoch [7/10], Step [200/938], Loss: 0.0330\n",
            "Epoch [7/10], Step [300/938], Loss: 0.2461\n",
            "Epoch [7/10], Step [400/938], Loss: 0.1097\n",
            "Epoch [7/10], Step [500/938], Loss: 0.2792\n",
            "Epoch [7/10], Step [600/938], Loss: 0.0804\n",
            "Epoch [7/10], Step [700/938], Loss: 0.2969\n",
            "Epoch [7/10], Step [800/938], Loss: 0.3505\n",
            "Epoch [7/10], Step [900/938], Loss: 0.1468\n",
            "Epoch [8/10], Step [100/938], Loss: 0.0967\n",
            "Epoch [8/10], Step [200/938], Loss: 0.0874\n",
            "Epoch [8/10], Step [300/938], Loss: 0.2915\n",
            "Epoch [8/10], Step [400/938], Loss: 0.1160\n",
            "Epoch [8/10], Step [500/938], Loss: 0.2445\n",
            "Epoch [8/10], Step [600/938], Loss: 0.1974\n",
            "Epoch [8/10], Step [700/938], Loss: 0.0464\n",
            "Epoch [8/10], Step [800/938], Loss: 0.1423\n",
            "Epoch [8/10], Step [900/938], Loss: 0.2958\n",
            "Epoch [9/10], Step [100/938], Loss: 0.2291\n",
            "Epoch [9/10], Step [200/938], Loss: 0.0228\n",
            "Epoch [9/10], Step [300/938], Loss: 0.0655\n",
            "Epoch [9/10], Step [400/938], Loss: 0.0236\n",
            "Epoch [9/10], Step [500/938], Loss: 0.1461\n",
            "Epoch [9/10], Step [600/938], Loss: 0.2613\n",
            "Epoch [9/10], Step [700/938], Loss: 0.0849\n",
            "Epoch [9/10], Step [800/938], Loss: 0.0975\n",
            "Epoch [9/10], Step [900/938], Loss: 0.0713\n",
            "Epoch [10/10], Step [100/938], Loss: 0.1116\n",
            "Epoch [10/10], Step [200/938], Loss: 0.0465\n",
            "Epoch [10/10], Step [300/938], Loss: 0.0668\n",
            "Epoch [10/10], Step [400/938], Loss: 0.0755\n",
            "Epoch [10/10], Step [500/938], Loss: 0.1748\n",
            "Epoch [10/10], Step [600/938], Loss: 0.0959\n",
            "Epoch [10/10], Step [700/938], Loss: 0.0764\n",
            "Epoch [10/10], Step [800/938], Loss: 0.0694\n",
            "Epoch [10/10], Step [900/938], Loss: 0.3185\n",
            "Accuracy of the network on the 10000 test images: 95.66 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import TensorDataset\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Load MNIST dataset and apply transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "\n",
        "train_dataset = datasets.MNIST(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.MNIST(root='./data', train=False, transform=transform)\n",
        "\n",
        "# Perform PCA on the dataset\n",
        "train_images = train_dataset.data.reshape(-1, 28 * 28).numpy()\n",
        "pca = PCA(n_components=20)\n",
        "train_pca = pca.fit_transform(train_images)\n",
        "\n",
        "test_images = test_dataset.data.reshape(-1, 28 * 28).numpy()\n",
        "test_pca = pca.transform(test_images)\n",
        "\n",
        "# Create new datasets with PCA-transformed data\n",
        "train_pca_dataset = TensorDataset(torch.from_numpy(train_pca).float(), train_dataset.targets)\n",
        "test_pca_dataset = TensorDataset(torch.from_numpy(test_pca).float(), test_dataset.targets)\n",
        "\n",
        "# Model parameters\n",
        "input_size = 20  # PCA component size\n",
        "hidden_size = 128\n",
        "num_layers = 2\n",
        "num_classes = 10\n",
        "batch_size = 64  # Define the batch size here\n",
        "num_epochs = 5\n",
        "\n",
        "# Define data loaders with PCA datasets\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_pca_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_pca_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Define LSTM model architecture with modified input size\n",
        "class LSTMNet(nn.Module):\n",
        "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
        "        super(LSTMNet, self).__init__()\n",
        "        self.input_size = input_size  # Assign input_size to an attribute\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = x.view(batch_size, -1, self.input_size)  # Reshape the input tensor\n",
        "        h0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "        c0 = torch.zeros(self.num_layers, batch_size, self.hidden_size).to(device)\n",
        "\n",
        "        out, _ = self.lstm(x, (h0, c0))\n",
        "        out = self.fc(out[:, -1, :])\n",
        "        return out\n",
        "\n",
        "# Initialize the LSTM model with modified input size\n",
        "model = LSTMNet(input_size, hidden_size, num_layers, num_classes).to(device)\n",
        "\n",
        "# Loss function and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(num_epochs):\n",
        "    for i, (images, labels) in enumerate(train_loader):\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "\n",
        "        # Backward and optimize\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if (i + 1) % 100 == 0:\n",
        "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{len(train_loader)}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Evaluation\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for images, labels in test_loader:\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    print(f'Accuracy on the test set: {accuracy:.2f}%')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dw6V3wXupSAY",
        "outputId": "386df086-c6fd-4941-bb55-1d5c3f5a9c72"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Step [100/938], Loss: 0.6845\n",
            "Epoch [1/5], Step [200/938], Loss: 0.3719\n",
            "Epoch [1/5], Step [300/938], Loss: 0.4686\n",
            "Epoch [1/5], Step [400/938], Loss: 0.3301\n",
            "Epoch [1/5], Step [500/938], Loss: 0.2429\n",
            "Epoch [1/5], Step [600/938], Loss: 0.2855\n",
            "Epoch [1/5], Step [700/938], Loss: 0.2752\n",
            "Epoch [1/5], Step [800/938], Loss: 0.3036\n",
            "Epoch [1/5], Step [900/938], Loss: 0.2735\n",
            "Epoch [2/5], Step [100/938], Loss: 0.2294\n",
            "Epoch [2/5], Step [200/938], Loss: 0.1860\n",
            "Epoch [2/5], Step [300/938], Loss: 0.2787\n",
            "Epoch [2/5], Step [400/938], Loss: 0.1761\n",
            "Epoch [2/5], Step [500/938], Loss: 0.1880\n",
            "Epoch [2/5], Step [600/938], Loss: 0.1296\n",
            "Epoch [2/5], Step [700/938], Loss: 0.2077\n",
            "Epoch [2/5], Step [800/938], Loss: 0.1525\n",
            "Epoch [2/5], Step [900/938], Loss: 0.1116\n",
            "Epoch [3/5], Step [100/938], Loss: 0.3791\n",
            "Epoch [3/5], Step [200/938], Loss: 0.1767\n",
            "Epoch [3/5], Step [300/938], Loss: 0.0718\n",
            "Epoch [3/5], Step [400/938], Loss: 0.1674\n",
            "Epoch [3/5], Step [500/938], Loss: 0.2880\n",
            "Epoch [3/5], Step [600/938], Loss: 0.1184\n",
            "Epoch [3/5], Step [700/938], Loss: 0.0891\n",
            "Epoch [3/5], Step [800/938], Loss: 0.1322\n",
            "Epoch [3/5], Step [900/938], Loss: 0.2185\n",
            "Epoch [4/5], Step [100/938], Loss: 0.1156\n",
            "Epoch [4/5], Step [200/938], Loss: 0.1675\n",
            "Epoch [4/5], Step [300/938], Loss: 0.0978\n",
            "Epoch [4/5], Step [400/938], Loss: 0.0836\n",
            "Epoch [4/5], Step [500/938], Loss: 0.2111\n",
            "Epoch [4/5], Step [600/938], Loss: 0.1523\n",
            "Epoch [4/5], Step [700/938], Loss: 0.3041\n",
            "Epoch [4/5], Step [800/938], Loss: 0.1554\n",
            "Epoch [4/5], Step [900/938], Loss: 0.0593\n",
            "Epoch [5/5], Step [100/938], Loss: 0.1849\n",
            "Epoch [5/5], Step [200/938], Loss: 0.0833\n",
            "Epoch [5/5], Step [300/938], Loss: 0.1581\n",
            "Epoch [5/5], Step [400/938], Loss: 0.1634\n",
            "Epoch [5/5], Step [500/938], Loss: 0.0940\n",
            "Epoch [5/5], Step [600/938], Loss: 0.1173\n",
            "Epoch [5/5], Step [700/938], Loss: 0.1656\n",
            "Epoch [5/5], Step [800/938], Loss: 0.1402\n",
            "Epoch [5/5], Step [900/938], Loss: 0.0580\n",
            "Accuracy on the test set: 94.98%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from itertools import combinations\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "\n",
        "# Load the dataset\n",
        "mnist = fetch_openml('mnist_784')\n",
        "X = mnist.data\n",
        "y = mnist.target.astype(int)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "\n",
        "from sklearn.decomposition import PCA\n",
        "# Apply PCA to reduce the dimensionality of the data\n",
        "pca = PCA(n_components=20)\n",
        "X_pca = pca.fit_transform(X)\n",
        "# Project the data onto 20 modes PCA space\n",
        "X_train_pca = pca.fit_transform(X_train)\n",
        "X_test_pca = pca.transform(X_test)\n",
        "\n",
        "# Create a function to train and test classifiers on digit pairs\n",
        "def test_digit_pairs(digit_pairs, classifier):\n",
        "    accuracy_scores = []\n",
        "    \n",
        "    for digit_pair in digit_pairs:\n",
        "        # Get the indices for the current digit pair\n",
        "        digit_indices = ((y_train == digit_pair[0]) | (y_train == digit_pair[1]))\n",
        "\n",
        "        # Create the feature and target datasets for the current digit pair\n",
        "        X_pair_train = X_train_pca[digit_indices]\n",
        "        y_pair_train = y_train[digit_indices]\n",
        "        X_pair_test = X_test_pca[((y_test == digit_pair[0]) | (y_test == digit_pair[1]))]\n",
        "        y_pair_test = y_test[((y_test == digit_pair[0]) | (y_test == digit_pair[1]))]\n",
        "\n",
        "        # Train the classifier on the training data\n",
        "        clf = classifier\n",
        "        clf.fit(X_pair_train, y_pair_train)\n",
        "\n",
        "        # Predict the labels of the test data\n",
        "        y_pred = clf.predict(X_pair_test)\n",
        "\n",
        "        # Calculate the accuracy of the classifier\n",
        "        accuracy = accuracy_score(y_pair_test, y_pred)\n",
        "\n",
        "        # Append the accuracy to the list of accuracy scores\n",
        "        accuracy_scores.append(accuracy)\n",
        "\n",
        "    # Calculate the average accuracy for all digit pairs\n",
        "    avg_accuracy = sum(accuracy_scores) / len(accuracy_scores)\n",
        "    print(f\"Average accuracy for all digit pairs: {avg_accuracy:.5f}\")\n",
        "\n",
        "# Test the SVM classifier on all digit pairs using 20 modes PCA\n",
        "svm_pairs = list(combinations(range(10), 2))\n",
        "svm_classifier = SVC()\n",
        "print(\"SVM\")\n",
        "test_digit_pairs(svm_pairs, svm_classifier)\n",
        "\n",
        "# Test the decision tree classifier on all digit pairs\n",
        "dt_pairs = list(combinations(range(10), 2))\n",
        "dt_classifier = DecisionTreeClassifier(random_state=42)\n",
        "print(\"Decision Tree\")\n",
        "test_digit_pairs(dt_pairs, dt_classifier)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHKudAv2uKVM",
        "outputId": "ecbbaba5-10ef-4174-d10a-de8d9a5b6b64"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/datasets/_openml.py:968: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
            "  warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SVM\n",
            "Average accuracy for all digit pairs: 0.99559\n",
            "Decision Tree\n",
            "Average accuracy for all digit pairs: 0.96874\n"
          ]
        }
      ]
    }
  ]
}